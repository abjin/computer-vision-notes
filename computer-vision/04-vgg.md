
# VGGNet 소개

- 단순한 깊은 네트워크가 특징
- 3x3 필터만 사용하는 단순한 구조를 가지고 있음


# VGG 설계 목표

- 연구 목표
  - 네트워크 **깊이와** 이미지 인식 정확도 영향 조사
- 고정된 설계
  - 모든 합성곱 층은 3x3 필터 사용, stride=1. padding=1
  - 고정된 설계는 공간 해상도를 안정적으로 유지하면서 더 깊은 쌓기를 가능하게 함
- 점진적 심화
  - VGG 모델은 11,13,16,19 가중치 계층으로 늘려 가며 구축
- 관찰
  - 깊이가 증가함에 따라 imageNet 에서 분류 오류가 일관되게 감소
  - 더 깊은 네트워크가 더 깊은 패턴을 포착하고 정확도를 향상 시키는 것을 확인



# VGG16 아키텍처 구성

### 개요
- 입력: 224×224 RGB 이미지
- 계층: 13개 합성곱 계층 + 3개 완전 연결 계층
- 합성곱 필터: 합성곱 계층은 3×3 필터 사용, 스트라이드 = 1, 패딩 = 1
- 풀링: 특정 합성곱 블록 후 최대 풀링: 2×2, 스트라이드 2
- 활성화: 각 합성곱 계층 후 ReLU 사용
- 더 깊은 모델에서 로컬 응답 정규화 (LRN) 없음


### 레이어별 세부 구조
- Conv1_1, Conv1_2: 64 filters → MaxPooling → 112 × 112 × 64  
- Conv2_1, Conv2_2: 128 filters → MaxPooling → 56 × 56 × 128  
- Conv3_1, Conv3_2, Conv3_3: 256 filters → MaxPooling → 28 × 28 × 256  
- Conv4_1, Conv4_2, Conv4_3: 512 filters → MaxPooling → 14 × 14 × 512  
- Conv5_1, Conv5_2, Conv5_3: 512 filters → MaxPooling → 7 × 7 × 512  
- FC1, FC2: 4096 neurons each  
- FC3: 1000 neurons → Softmax


| 블록                      | 필터 수         | Pooling 후 출력 크기    |
|---------------------------|-----------------|------------------------|
| Conv1_1, Conv1_2          | 64              | 112 × 112 × 64         |
| Conv2_1, Conv2_2          | 128             | 56 × 56 × 128          |
| Conv3_1, Conv3_2, Conv3_3 | 256             | 28 × 28 × 256          |
| Conv4_1, Conv4_2, Conv4_3 | 512             | 14 × 14 × 512          |
| Conv5_1, Conv5_2, Conv5_3 | 512             | 7 × 7 × 512            |
| FC1, FC2                  | 4096 neurons    | -                      |
| FC3                       | 1000 neurons    | -                      |

### 완전 연결 계층
- 구조
  - 합성곱 계층에서 편평화된 출력: 7 × 7 × 512 = 25,088
  - FC1: 4096 유닛 + ReLU + 드롭아웃 (p = 0.5)
  - FC2: 4096 유닛 + ReLU + 드롭아웃 (p = 0.5)
  - FC3: 1000 유닛 (분류용) + 소프트맥스

- 특징
  - VGG 모델의 대부분의 파라미터가 FC 계층에 포함됨
  - ReLU는 더 빠른 훈련을 가능하게 하고 비선형성을 도입
  - 드롭아웃은 과적합 감소에 도움
  - 이 FC 계층은 나중에 합성곱 계층으로 변환되어 완전 합성곱 네트워크를 형성할 수 있음



# VGG 의 핵심 아이디어

## 쌓아올린 3x3 합성곱층

### 핵심 아이디어

- 작은 필터를 여러겹 쌓아 큰 필터가 가지는 수용 영역을 커버할 수 있음
- 작은 필터를 여러겹 쌓으면 더 많은 비선형성을 가짐 -> 모델이 복잡한 패턴을 학습할 수 있는 능력을 증가
- 작은 필터를 여러겹 쌓으념 더 적은 파라미터 사용함 -> 오버피팅 위험 감소

  
##### 수용 필드 비교

- 두 개 3×3 합성곱 쌓기 = 5×5 수용 필드
- 세 개 3×3 합성곱 쌓기 = 7×7 수용 필드

| 필터 전략          | 유효 수용 필드 | 비선형 계층 수 | 파라미터 (채널당) |
| -------------- | -------- | -------- | ---------- |
| 하나의 5×5 합성곱    | 5×5      | 1        | 5×5×C×C    |
| 쌓인 두 개 3×3 합성곱 | 5×5      | 2        | 2×3×3×C×C  |
| 하나의 7×7 합성곱    | 7×7      | 1        | 7×7×C×C    |
| 쌓인 세 개 3×3 합성곱 | 7×7      | 3        | 3×3×3×C×C  |

### 3x3 쌓기의 이점

- 비선형성 증가
- 파라미터 수 감소
- 더 빠른 훈련
- 모듈식 설계 가능


## 드롭아웃

### 개념
- 드롭아웃은 신경망에서 사용되는 정규화 기법
- 훈련중 특정 확률로 뉴런을 무작위로 "드롭아웃" 시켜 작동
- 드롭된 뉴런은 일시적올 제거되어 해당 훈련 단계에서 순전파나 역전파에 참여하지 않음
- 드롭되는 특정 뉴런은 훈련 방봅마다 변경될 수 있음
### 특징
- 드롭아웃 비율은 하이퍼파라미터이다. (일반적으로 0.5로 설정함)
- 훈련중에 특정 뉴런에만 의존하는 것을 방지하고 강건하고 일반적인 특징을 학습하도록 함
- 테스트에는 드롭아웃이 적요되지 않음 (모든 뉴런을 사용, 모든 뉴런활성 -> 출력값 커짐 -> 스케일링 사용)
- 특정 강한 특징에 대한 의존도를 줄여 과접합을 방지
- 각기 다른 뉴런 조합을 매번 훈련하기 때문에 앙상불 효과 발생시킴

### 효과 - 과적합 방지
- 드롭아웃 없으면 특정 강한 특징에 의존성이 생겨 과접합이 될 수 있음
- 오버피팅은 안본 데이터에 대한 모델 성능을 떨어트림
- 특정 뉴런에 매번 의존 할 수 없게 만들어서 강건한 특징을 학습하도록 함

### 효과 - 앙상블 효과
- 각 무작위 드롭아웃 구성은 서로 다른 서브네트워크를 생성
- 훈련 중에 네트워크는 많은 서브네트워크들을 병렬로 최적화
- 테스트시에는 모든 뉴련이 사용됨, 이는 모든 서브네트워크들의 출력을 평균하는 것과 유사
- 이 과정은 모델의 앙상블처럼 작동하여 정확도를 향상하고 편향을 감소 



## 미니배치 훈련에서 드롭아웃

### 어떻게 작동하는가?
- 드롭아웃은 미니배치에 독립적으로 적용
- 드롭아웃 비율 0.5로 각 뉴런은 모든 배치에서 50% 확률로 드롭될 수 있음
- 드롭되는 뉴런은 다른 배치에서 다를 수 있음
- 이 무작위성은 네트워크가 모든 훈련 데이터에서 특정 뉴런에 의존하지 않도록 보장


### 중요성
- 정 정보를 한 뉴런에만 맡기지 않고 여러 뉴런이 겹쳐서 나누어 표현하게 만듦
- 이로 인하여 단일 경로가 학습 과정을 지배할 수 없으므로 더 강건한 일반화로 이어짐
- 각 미니배치가 다른 서브네트워크를 훈련하므로 드롭아웃은 네트워크 앙상블 훈련 효과를 생성
-  테스트 시 모든 뉴런이 함께 사용될 때 모델은 평균화된 앙상블처럼 작동하여 안정성과 정확도를 향상



### 스케일링

- 훈련 중에 일부 뉴런은 확률 α(드롭아웃 비율)로 무작위로 드롭됨
- 테스트(추론) 중에는 모든 뉴런이 활성화되지만 출력은 훈련의 기대값과 일치하도록 스케일링됨

$$
h_n = (1 - α) * a(w_n * h_{n-1} + b_n)
$$
- a는 활성화 함수, α는 드롭아웃 비율
- (1 - α) 인자는 테스트 시 평균 활성화가 훈련과 일치하도록 출력을 조정

- 훈련 중에는 더 적은 뉴런이 활성화되기 때문에 출력이 작음
- 테스트중에는 모든 뉴런이 활성화 되기 때문에 출력이 큼
- 출력의 크기를 동일하게 맞추기 위해 (1 - α) 를 곱해줌


## 데이터 증강

### 데이터 증강 기법

- Resize: 이미지 크기를 통일 (최소 256px 이상)
- Random crop: 224×224 크기로 무작위 영역 추출 → 위치 불변성 학습
- Random horizontal flip: 50% 확률로 좌우 반전 → 방향성 일반화
- Color jittering: 밝기, 대비, 채도, 색조 무작위 변형 → 조명 환경 견고화

### 스케일 지터링(Scale Jittering)

- 단일 스케일: 이미지 크기를 256으로 고정 → 빠름 but 특정 크기에만 취약
- 멀티 스케일: 256~512 사이 무작위 크기로 리사이즈 → 다양한 크기에 강건, 일반화 성능 향상

- 멀티 스케일이 단일 스케일보다 분류 정확도를 향상시키는 것으로 나타남

### 장점
- 데이터 셋의 다양성 증가
- 다양한 객체 컨텍스트 포착
	- 작은 자르기 -> 큰 개체
	- 큰 자르기 -> 작은 개체
- 과접합 감소에 도움이 된다


# VGG16 VS VGG19

- 공통 특징
  - 입력: 둘 다 224×224 RGB 이미지를 입력으로 받음
  - 합성곱 커널: 전체 네트워크에서 3×3 합성곱 커널만 사용
  - 폴링: 5개 최대 풀링 계층 포함
  - FC: 3개 완전 연결 계층으로 끝남: 4096 → 4096 → 1000
  - 활성화 함수: 각 합성곱 계층 후 ReLU 활성화 사용
  - 로컬 응답 정규화: 둘다 로컬 응답 정규화 없음


- VGG16
  - 13개 합성곱 계층 + 3개 완전 연결 계층
  - 총 16개 가중치 계층
  - 합성곱 블록: 2-2-3-3-3 패턴

- VGG19
  - 16개 합성곱 계층 + 3개 완전 연결 계층
  - 총 19개 가중치 계층
  - 합성곱 블록: 2-2-4-4-4 패턴


# VGG vs AlexNet

- AlexNet 과 차이점
  - VGG 가 훨씬더 깊음 (AlexNet: 8개, VGG: 16/19)
  - VGG 가 더 단순하고 균일한 설계
  - VGG 가 층이 많아 복잡하지만 작은 필터와 반복적인 규칙적 구조 덕분에 더 좋은 성능을 냄
